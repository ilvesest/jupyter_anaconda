{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts for automatic job searching through job websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "code_folding": [
     15,
     40,
     50,
     56,
     75,
     94,
     105,
     107,
     109
    ]
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException \n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "def by_xpath(xpath, fill=None, enter=False, wait=0):\n",
    "    '''Fills in an input field or clicks on an icon.'''\n",
    "    \n",
    "    try:\n",
    "        elem = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, xpath))) # finds the specified field\n",
    "    finally:\n",
    "        if fill != None:\n",
    "            elem.click()\n",
    "            elem.clear()\n",
    "            elem.send_keys(fill)\n",
    "            sleep(wait)\n",
    "            if enter == True:\n",
    "                elem.send_keys(Keys.RETURN)\n",
    "            \n",
    "        else:\n",
    "            if enter == True:\n",
    "                elem.click()\n",
    "                sleep(1)\n",
    "                elem.send_keys(Keys.RETURN)\n",
    "            else:\n",
    "                sleep(wait)\n",
    "                elem.click()\n",
    "    return None\n",
    "\n",
    "def if_element(xpath):\n",
    "    '''Determines if element present in page.'''\n",
    "    \n",
    "    try:\n",
    "        time.sleep(3)\n",
    "        driver.find_element_by_xpath(xpath)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def elem_siblings(url, tag, class_):\n",
    "    '''Returns the number siblings of given html block'''\n",
    "    \n",
    "    soup = bs((requests.get(url)).text)\n",
    "    return len(soup.find(tag, class_=class_))\n",
    "\n",
    "def jobs_tofile(filename, keyword, location):\n",
    "    '''Extracts job headlines and their hrefs from web page\n",
    "    \n",
    "    Parameters:\n",
    "        filename - [str] name of the file without extention\n",
    "        head - [boolean] weather to append df with or withoud header\n",
    "        \n",
    "    Returns: None'''\n",
    "    \n",
    "    current_date = datetime.now().strftime(\"%d-%b\") # current date [Day - Month]\n",
    "    soup = bs((requests.get(driver.current_url)).text) # soup object\n",
    "\n",
    "    headlines = [(block.h3.get_text(), keyword, location, block['href']) for block in soup.find_all('a', \n",
    "        class_=re.compile(\"listed-job-posting listed-job-posting--is-link*\"))]\n",
    "    \n",
    "    df = pd.DataFrame(headlines, columns=['job_title', 'keyword', 'location', 'href'])\n",
    "    df.to_csv(filename + '_' + current_date + '.csv', sep='\\t', \n",
    "              encoding='utf-8', mode='a', header=False, index=False)\n",
    "\n",
    "def scan_pages(keyword, location, filename):\n",
    "    '''Clicks through all pages and extracts jobs from them.'''\n",
    "    \n",
    "    nr_of_pages = elem_siblings(driver.current_url, 'ul', class_='pagination__pages')\n",
    "    \n",
    "    if nr_of_pages == 1:\n",
    "        jobs_tofile(filename, keyword, location)\n",
    "        return False\n",
    "    else:\n",
    "        for page in range(2, nr_of_pages + 1):\n",
    "    \n",
    "            try:\n",
    "                elem = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, '//a[contains(text(),\"{}\")]'.format(page))))\n",
    "            finally:\n",
    "                elem.click()\n",
    "            jobs_tofile(filename, keyword, location)\n",
    "    return True\n",
    "\n",
    "def show_jobs(filename):\n",
    "    '''Prints out DF of jobs.\n",
    "        Parameters:\n",
    "            filename : [str]\n",
    "        Returns None'''\n",
    "    current_date = datetime.now().strftime(\"%d-%b\") # current date [Day - Month]\n",
    "    \n",
    "    df = pd.read_csv(filename + '_' + current_date + '.csv', sep='\\t', header=None,\n",
    "                    names=['job_title', 'keyword', 'location', 'href'])\n",
    "    print(df)\n",
    "\n",
    "def search_jobs(url, keywords, locations, filename, date='week'):\n",
    "    '''Finds jobs on linkedin, stores into .csv \n",
    "    file and prints out the resulting DF.\n",
    "        \n",
    "        Parameters:\n",
    "            url : [str] web page address with search options.\n",
    "            keywords: [list] job titles.\n",
    "            locations: [list] locations / regions /states.\n",
    "            filename: [str] name of the file where data is printed.\n",
    "            date : [str] \"24\"    : past 24 hours\n",
    "                         \"week   : past week\n",
    "                         \"month\" : past month\n",
    "                         \"any\"   : anytime\n",
    "                         \n",
    "        Returns None'''\n",
    "    \n",
    "    dates = {'24' : '0','week' : '1','month' : '2','any' : '3'}\n",
    "    \n",
    "    assert type(keywords) == list, \"Error, keyword not 'list' type!\"\n",
    "    assert type(locations) == list, \"Error, locations not 'list' type!\"\n",
    "    assert date in dates, 'Error, no such date! Use either:\\n\"24\", \"week\", \"month\", \"any\"'\n",
    "    \n",
    "    driver.get(url) # navigates to gven URL\n",
    "    \n",
    "    for i, location in enumerate(locations):\n",
    "        for j, keyword in enumerate(keywords):\n",
    "            \n",
    "            # filling search fields\n",
    "            sleep(2)\n",
    "            by_xpath('//*[@id=\"keyword-box-input\"]', fill=keyword)\n",
    "            by_xpath('//*[@id=\"location-box-input\"]', fill=location)\n",
    "            by_xpath('//button[@type=\"submit\"]')\n",
    "            \n",
    "            if i + j == 0:\n",
    "                by_xpath('//*[@id=\"location-box-input\"]', fill=location) # buggy\n",
    "                by_xpath('//button[@type=\"submit\"]')\n",
    "                \n",
    "                # filters\n",
    "                by_xpath('//button[text()=\"Date Posted\"]') # which period\n",
    "                by_xpath('//label[@for=\"TIME_POSTED-{}\"]'.format(dates[date]))\n",
    "                by_xpath('//button[@type=\"submit\"][contains(text(),\"Apply\")]')\n",
    "                by_xpath('//button[text()=\"Experience Level\"]') # exp levels\n",
    "                by_xpath(\"//label[@for='EXPERIENCE-0']\")\n",
    "                by_xpath(\"//label[@for='EXPERIENCE-1']\")\n",
    "                by_xpath(\"/html/body/main/section[2]/div/div[2]/div[1]/ul/li[4]\"\n",
    "                         \"/form/div/div/fieldset/div[2]/button[2]\")\n",
    "                by_xpath('//select[@id=\"sort-options\"]') # sort by date\n",
    "                by_xpath('//option[@value=\"DD\"]')\n",
    "                \n",
    "                jobs_tofile(filename, keyword, location)\n",
    "                scan_pages(keyword, location, filename)\n",
    "            else:\n",
    "                scan_pages(keyword, location, filename)\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox() # setting up the driver\n",
    "\n",
    "search_jobs(url=\"https://ca.linkedin.com/jobs/\",\n",
    "            keywords=['Data Scientist', 'Machine Learning', 'Data Analyst'],\n",
    "            locations=['British Columbia', 'Alberta'],\n",
    "            filename='linkedin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing LinkedIn without logging in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# setting up the driver\n",
    "driver = webdriver.Firefox()\n",
    "\n",
    "# The driver.get method will navigate to a page given by the URL.\n",
    "driver.get(\"https://ca.linkedin.com/jobs/\")\n",
    "\n",
    "# search field\n",
    "by_xpath('//*[@id=\"keyword-box-input\"]', fill='Data Scientist')\n",
    "by_xpath('//*[@id=\"location-box-input\"]', fill='British Columbia')\n",
    "by_xpath('//button[@type=\"submit\"]')\n",
    "\n",
    "# for some reason theres a bug and have to fill one field again\n",
    "by_xpath('//*[@id=\"location-box-input\"]', fill='British Columbia')\n",
    "by_xpath('//button[@type=\"submit\"]')\n",
    "\n",
    "# date posted\n",
    "by_xpath('//button[text()=\"Date Posted\"]')\n",
    "by_xpath('//label[@for=\"TIME_POSTED-0\"]')\n",
    "by_xpath('//button[@type=\"submit\"][contains(text(),\"Apply\")]')\n",
    "\n",
    "# experience levels\n",
    "by_xpath('//button[text()=\"Experience Level\"]')\n",
    "by_xpath(\"//label[@for='EXPERIENCE-0']\")\n",
    "by_xpath(\"//label[@for='EXPERIENCE-1']\")\n",
    "#by_xpath(\"//button[@type='submit'][contains(text(),'Apply')]\", enter=True)\n",
    "by_xpath(\"/html/body/main/section[2]/div/div[2]/div[1]/ul/li[4]/form/div/div/fieldset/div[2]/button[2]\")\n",
    "\n",
    "# sort by\n",
    "by_xpath('//select[@id=\"sort-options\"]')\n",
    "by_xpath('//option[@value=\"DD\"]')\n",
    "\n",
    "# read off job titles and hrefs from each page\n",
    "nr_of_pages = elem_siblings(driver.current_url, 'ul', class_='pagination__pages')\n",
    "jobs_tofile('linkedin', 'Data Scientist', 'British Columbia', head=True)\n",
    "for page in range(2, nr_of_pages + 1):\n",
    "    \n",
    "    try:\n",
    "        elem = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//a[contains(text(),\"{}\")]'.format(page))))\n",
    "    finally:\n",
    "        elem.click()\n",
    "    #by_xpath('//a[contains(text(),\"{}\")]'.format(page))\n",
    "    jobs_tofile('linkedin')\n",
    "    \n",
    "driver.quit()\n",
    "\n",
    "# show_jobs('linkedin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
