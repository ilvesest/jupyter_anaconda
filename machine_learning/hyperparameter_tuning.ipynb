{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center><font size='30'>Hyperparameter Tuning</font></center>**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Based Models\n",
    "With tree based models the order the parameters are tuned is important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoosting\n",
    "We use **Aarshay Jain** (2016) guide [Complete Machine Learning Guide to Parameter Tuning in Gradient Boosting (GBM) in Python](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/)\n",
    "Parameters can be divided into 3 categories:\n",
    "* **Tree-Specific**:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "**eXtreme Gradient Boosting**<br>\n",
    "Parameter categories:<br>\n",
    "<br>\n",
    "**General Parameters**\n",
    "* **booster** - model type\n",
    "    * gbtree: tree-based\n",
    "    * gblinear: linear\n",
    "    * dart: **<code><font color='green'>pass</font></code>**\n",
    "* **n_jobs** - number of cores to be used, \"-1\" uses all cores<br>\n",
    "\n",
    "(Tree)**Booster Parameters**\n",
    "* **learning_rate** - amount of observations weight change after each tree (step)\n",
    "* **min_child_weight** - minimum sum of weights of all observations required in a child. Regularization against **over-fitting**. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree. Quoting **hahdawg** [Explanation of min_child_weight in xgboost algorithm](https://stats.stackexchange.com/questions/317073/explanation-of-min-child-weight-in-xgboost-algorithm): \"Stop trying to split once you reach a certain degree of purity in a node and your model can fit it.\"\n",
    "* **max_depth** - max tree depth\n",
    "* **gamma** - minimum loss reduction required to split a node\n",
    "* **subsample** - random fraction of observations for each tree\n",
    "* **colsample_bytree** - fraction of n_features\n",
    "* **reg_lambda** - L2 regularization term on weights (Ridge)\n",
    "* **reg_alpha** - L1 regularization term on weights (Lasso)\n",
    "\n",
    "**Learning Task Parameters**\n",
    "* **objective** - loss function to be minimized\n",
    "* **eval_metric** - metric to be used for validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter Tuning Steps**\n",
    "0. Set initial parameter values.\n",
    "1. Choose **high** <code>learning_rate</code> ~0.1 and \n",
    "    * determine optimum <code>n_estimators</code> for that learning rate.\n",
    "2. Tune simultaenously:\n",
    "    * <code>max_depth</code>\n",
    "    * <code>min_child_weight</code>\n",
    "3. Tune <code>gamma</code>\n",
    "4. Calibrate <code>n_estimators</code>\n",
    "5. Tune simultaenously\n",
    "    * <code>subsample</code>\n",
    "    * <code>colsample_bytree</code>\n",
    "6. Tune regularization params\n",
    "    * <code>reg_alpha</code>\n",
    "    * <code>reg_lambda</code>\n",
    "7. Reduce <code>learning_rate</code> and increase <code>n_estimators</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.sklearn.XGBRegressor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
