{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    " * Parameters, which needed to be specified before fitting a model (like ùõº in Ridge and Lasso regression or 'k' in kNN) are called hyperparameters.\n",
    " * These are parameters which cannot be learned by fitting the model.\n",
    " \n",
    "#### Basic idea:\n",
    "     1. Try a bunch of different values for the parameters\n",
    "     2. Fit all them separately\n",
    "     3. Check how well each performs \n",
    "     4. Choose the best one\n",
    "     \n",
    "**NB!** When fitting different values of hyperparameter it is essential to use cross-validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV\n",
    "\n",
    " * Like the ùõº parameter of Lasso and Ridge regularization, logistic regression also has a regularization parameter: C.\n",
    " * C controls the inverse of the regularization strength.\n",
    " * A large C can lead to an overfit model, while a small C can lead to an underfit model.\n",
    " \n",
    "<img src=\"classification/img/grid_cv.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
       "0            6      148         72       35        0  33.6  0.627   50   \n",
       "1            1       85         66       29        0  26.6  0.351   31   \n",
       "\n",
       "   diabetes  \n",
       "0         1  \n",
       "1         0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use diabetes.csv dataset\n",
    "diab = pd.read_csv('classification/data/diabetes.csv', header=0)\n",
    "diab.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 31.622776601683793}\n",
      "\n",
      "Best score is 0.760\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "X = diab.drop('diabetes', axis=1)\n",
    "y = diab.diabetes\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n",
    "    random_state=0)\n",
    "\n",
    "# setup hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C' : c_space}\n",
    "\n",
    "# init logistic regression classifier\n",
    "logist_reg = linear_model.LogisticRegression(solver='liblinear')\n",
    "\n",
    "# init GridSearchCV object\n",
    "logist_reg_cv = model_selection.GridSearchCV(\n",
    "    estimator=logist_reg, param_grid=param_grid, cv=5, return_train_score=False)\n",
    "\n",
    "# fit to the data\n",
    "logist_reg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logist_reg_cv.best_params_))\n",
    "print(\"\\nBest score is {:.3f}\".format(logist_reg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB!** GridSearchCV can be computationally expensive. A solution to this is to use RandomizedSearchCV.\n",
    "\n",
    "## RandomizedSearchCV\n",
    "\n",
    " * Not all hyperparameter values are tried out.\n",
    " * A fixed number of hyperparameter settings is sampled from specified probability distributions.\n",
    " \n",
    "Find optimal hyperparameters with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'gini', 'max_depth': 3, 'max_features': 5, 'min_samples_leaf': 3}\n",
      "Best score is 0.75\n"
     ]
    }
   ],
   "source": [
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5, return_train_score=False)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    " * RandomizedSearchCV will never outperform GridSearchCV\n",
    " * Saves computation time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice GridSearchCV with LogisiticRegression\n",
    "\n",
    " * In addition to C , logistic regression has a 'penalty' hyperparameter which specifies whether to use 'l1' or 'l2' regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 31.622776601683793, 'penalty': 'l2'}\n",
      "Tuned Logistic Regression Accuracy: 0.7673337648793469\n"
     ]
    }
   ],
   "source": [
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logreg = linear_model.LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Create train and test sets, he test set here will function as the hold-out set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5, iid=False)\n",
    "\n",
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice GridSearchCV with Regression\n",
    "\n",
    " * Lasso used the L1 penalty to regularize, while ridge used the L2 penalty.\n",
    " * There is another type of regularized regression known as the **elastic net**. \n",
    " * In elastic net regularization, the penalty term is a linear combination of the L1 and L2\n",
    " \n",
    " $$\\text{Elastic Net} = aL_1 + bL_2$$\n",
    " <br>\n",
    " * In scikit-learn, this term is represented by the 'L1_ratio' parameter: \n",
    " \n",
    " $$ \\text{L1_ratio} = \\frac{a}{a+b} $$\n",
    " <br>\n",
    " * An 'L1_ratio' of 1 corresponds to an L1 penalty, and anything lower is a combination of L1 and L2.\n",
    " \n",
    "##### Let's tune the 'l1_ratio' of an elastic net model trained on the Gapminder data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>fertility</th>\n",
       "      <th>HIV</th>\n",
       "      <th>CO2</th>\n",
       "      <th>BMI_male</th>\n",
       "      <th>GDP</th>\n",
       "      <th>BMI_female</th>\n",
       "      <th>life</th>\n",
       "      <th>child_mortality</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34811059.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.328945</td>\n",
       "      <td>24.59620</td>\n",
       "      <td>12314.0</td>\n",
       "      <td>129.9049</td>\n",
       "      <td>75.3</td>\n",
       "      <td>29.5</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19842251.0</td>\n",
       "      <td>6.43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.474353</td>\n",
       "      <td>22.25083</td>\n",
       "      <td>7103.0</td>\n",
       "      <td>130.1247</td>\n",
       "      <td>58.3</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  fertility  HIV       CO2  BMI_male      GDP  BMI_female  life  \\\n",
       "0  34811059.0       2.73  0.1  3.328945  24.59620  12314.0    129.9049  75.3   \n",
       "1  19842251.0       6.43  2.0  1.474353  22.25083   7103.0    130.1247  58.3   \n",
       "\n",
       "   child_mortality                      Region  \n",
       "0             29.5  Middle East & North Africa  \n",
       "1            192.0          Sub-Saharan Africa  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data as DF\n",
    "gapminder = pd.read_csv('regression/data/gm_2008_region.csv', header=0)\n",
    "gapminder.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonu_ilves/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/tonu_ilves/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/tonu_ilves/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/tonu_ilves/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/tonu_ilves/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'l1_ratio': array([0.     , 0.03448, 0.06897, 0.10345, 0.13793, 0.17241, 0.2069 ,\n",
       "       0.24138, 0.27586, 0.31034, 0.34483, 0.37931, 0.41379, 0.44828,\n",
       "       0.48276, 0.51724, 0.55172, 0.58621, 0.62069, 0.65517, 0.68966,\n",
       "       0.72414, 0.75862, 0.7931 , 0.82759, 0.86207, 0.89655, 0.93103,\n",
       "       0.96552, 1.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features and target\n",
    "X = gapminder.drop(['life', 'Region'], axis=1).values\n",
    "y = gapminder.life.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# init Elastic Net object\n",
    "elastic_net = linear_model.ElasticNet()\n",
    "\n",
    "# create hyperparameter space\n",
    "l1_space = np.linspace(0, 1, 30)\n",
    "\n",
    "param_grid = {'l1_ratio' : l1_space}\n",
    "\n",
    "# Setup the GridSearchCV object: gm_cv\n",
    "gm_cv = GridSearchCV(estimator=elastic_net, param_grid=param_grid, cv=5, \n",
    "                     return_train_score=False, iid=False)\n",
    "\n",
    "gm_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net l1_ratio = 0.207\n",
      "Elastic Net R^2 = 0.867\n",
      "Elastic Net RMSE = 10.058\n"
     ]
    }
   ],
   "source": [
    "y_pred = gm_cv.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Predict on the test set and compute metrics R^2 and RMSE\n",
    "print(\"Elastic Net l1_ratio = {:.3f}\".format(gm_cv.best_params_['l1_ratio']))\n",
    "print(\"Elastic Net R^2 = {:.3f}\".format(gm_cv.score(X_test, y_test)))\n",
    "print(\"Elastic Net RMSE = {:.3f}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ratio is more toward 0 the Elstic Net regressor is mostly using Ridge regressor over Lasso. WIth this example we end up with:\n",
    "\n",
    "$$\\text{Elastic Net} = 0.2L_1 + 0.8L_2$$ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
